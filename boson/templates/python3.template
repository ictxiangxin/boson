{% if code_comment -%}
"""
    {{ configure.boson_title }} - {{ configure.boson_description }}

        Author: {{ configure.boson_author }}
        Email:  {{ configure.boson_email }}
        Site:   {{ configure.boson_url }}

    These codes are generated by the boson Python3 code generator.
        {% for sentence in analyzer_table.sentence_list %}
        {{ ('%%%dd' % reduce_number_width) % loop.index0 }}: {{ sentence[0] }} -> {% for element in sentence[1:] -%}
                                                                                  {%- if element in grammar_package.literal_reverse_map -%}
                                                                                  '{{ grammar_package.literal_reverse_map[element] }}'
                                                                                  {%- else -%}
                                                                                  {{ element }}
                                                                                  {%- endif -%}
                                                                                  {%- if not loop.last %} {% endif -%}
                                                                                  {%- endfor -%}
        {%- endfor %}
"""


{% endif -%}
class {{ configure.boson_option['lexical_token_class_name'] }}:
    text: str
    line: int
    symbol: str

    def __init__(self, text: str, line: int, symbol: str):
        self.text = text
        self.line = line
        self.symbol = symbol


{% if generate_lexical_analyzer -%}
class {{ configure.boson_option['lexical_analyzer_class_name'] }}:
    def __init__(self):
        self.__token_list = []
        self.__line = {{ configure.boson_lexical_start_line }}
        self.__error_line = {{ configure.boson_lexical_no_error_line }}
        self.__no_error_line = {{ configure.boson_lexical_no_error_line }}
        self.__skip = {{ configure.boson_lexical_default_skip }}
        self.__move_table = {
            {%- for state, state_move_table in lexical_package.compact_move_table.items() %}
            {{ state }}: [
                {%- for each in state_move_table %}
                {{ each }}
                {%- if not loop.last %},{% endif -%}
                {%- endfor %}
            ]
            {%- if not loop.last %},{% endif -%}
            {%- endfor %}
        }
        self.__character_set = {{ lexical_package.character_set }}
        self.__start_state = {{ lexical_package.start_state }}
        self.__end_state_set = {{ lexical_package.end_state_set }}
        self.__lexical_symbol_mapping = {
            {%- for state, symbol in lexical_package.lexical_symbol_mapping.items() %}
            {{ state }}: '{{ symbol }}'
            {%- if not loop.last %},{% endif -%}
            {%- endfor %}
        }
        self.__non_greedy_state_set = {{ lexical_package.non_greedy_state_set }}
        self.__symbol_function_mapping = {
            {%- for symbol, function_list in lexical_package.symbol_function_mapping.items() %}
            '{{ symbol }}': {{ function_list }}
            {%- if not loop.last %},{% endif -%}
            {%- endfor %}
        }
        self.__lexical_function = {}

    def _invoke_lexical_function(self, symbol: str, token_string: str):
        self.__skip = {{ configure.boson_lexical_default_skip }}
        if symbol in self.__symbol_function_mapping:
            for function in self.__symbol_function_mapping[symbol]:
                if function in self.__lexical_function:
                    token_string = self.__lexical_function[function](token_string)
                elif function == 'skip':
                    self.skip()
                elif function == 'newline':
                    self.newline()
        return token_string

    def _generate_token(self, state: int, token_string: str):
        symbol = self.__lexical_symbol_mapping.get(state, '{{ configure.boson_default_symbol }}')
        token_string = self._invoke_lexical_function(symbol, token_string)
        if not self.__skip:
            self.__token_list.append({{ configure.boson_option['lexical_token_class_name'] }}(token_string, self.__line, symbol))

    def skip(self):
        self.__skip = True

    def newline(self):
        self.__line += 1

    def token_list(self):
        return self.__token_list

    def error_line(self):
        return self.__error_line

    def no_error_line(self):
        return self.__no_error_line

    def tokenize(self, text: str):
        self.__token_list = []
        self.__error_line = self.__no_error_line
        self.__line = {{ configure.boson_lexical_start_line }}
        state = self.__start_state
        token_string = ''
        index = 0
        while index < len(text):
            character = text[index]
            index += 1
            get_token = False
            if state in self.__non_greedy_state_set:
                get_token = True
            if not get_token and state in self.__move_table:
                for attribute, character_set, range_list, next_state in self.__move_table[state]:
                    if attribute == 2:
                        condition = character not in character_set
                        for min_character, max_character in range_list:
                            condition &= character < min_character or character > max_character
                    else:
                        condition = character in character_set
                        if attribute == 1 and character not in self.__character_set:
                            condition = True
                        for min_character, max_character in range_list:
                            if condition or min_character <= character <= max_character:
                                condition = True
                                break
                    if condition:
                        token_string += character
                        state = next_state
                        break
                else:
                    if state in self.__end_state_set:
                        get_token = True
                    else:
                        self.__error_line = self.__line
                        return self.__error_line
            else:
                if get_token or state in self.__end_state_set:
                    get_token = True
                else:
                    raise ValueError('Invalid state: state={}'.format(state))
            if get_token:
                self._generate_token(state, token_string)
                token_string = ''
                state = self.__start_state
                index -= 1
        if state in self.__end_state_set:
            self._generate_token(state, token_string)
        else:
            raise ValueError('Invalid state: state={}'.format(state))
        self.__token_list.append({{ configure.boson_option['lexical_token_class_name'] }}('', self.__line, '{{ configure.boson_end_symbol }}'))
        return self.__error_line

    def lexical_function_entity(self, function_name):
        def decorator(f):
            self.__lexical_function[function_name] = f
            return f
        return decorator


{% endif -%}
class {{ configure.boson_option['grammar_class_name'] }}:
    def __init__(self):
        self.__grammar_tree = None
        self.__error_index = {{ configure.boson_grammar_no_error_index }}
        self.__no_error_index = {{ configure.boson_grammar_no_error_index }}

    def get_grammar_tree(self):
        return self.__grammar_tree

    def set_grammar_tree(self, grammar_tree: tuple):
        self.__grammar_tree = grammar_tree

    grammar_tree = property(get_grammar_tree, set_grammar_tree)

    def get_error_index(self):
        return self.__error_index

    def set_error_index(self, error_index: int):
        self.__error_index = error_index

    error_index = property(get_error_index, set_error_index)

    def no_error_index(self):
        return self.__no_error_index


class {{ configure.boson_option['grammar_node_class_name'] }}:
    def __init__(self):
        self.reduce_number = -1
        self.__data = []

    def __getitem__(self, item):
        return self.__data[item]

    def __iadd__(self, other):
        self.__data += other
        return self

    def append(self, item):
        self.__data.append(item)

    def insert(self, index, item):
        self.__data.insert(index, item)

    def data(self):
        return self.__data


class {{ configure.boson_option['grammar_analyzer_class_name'] }}:
    def __init__(self):
        self.__terminal_index = {
            {%- for terminal, index in analyzer_table.terminal_index.items() %}
            '{{ terminal }}': {{ index }}
            {%- if not loop.last %},{% endif -%}
            {%- endfor %}
        }
        {%- if sparse_table %}
        self.__action_table = {
            {%- for i, sub_table in analyzer_table.action_table.items() %}
            {{ i }}: {{ sub_table }}
            {%- if not loop.last %},{% endif -%}
            {%- endfor %}
        }
        self.__goto_table = {
            {%- for i, sub_table in analyzer_table.goto_table.items() %}
            {{ i }}: {{ sub_table }}
            {%- if not loop.last %},{% endif -%}
            {%- endfor %}
        }
        {%- else %}
        self.__action_table = [
            {%- for line in analyzer_table.action_table %}
            {{ line }}
            {%- if not loop.last %},{% endif -%}
            {%- endfor %}
        ]
        self.__goto_table = [
            {%- for line in analyzer_table.goto_table %}
            {{ line }}
            {%- if not loop.last %},{% endif -%}
            {%- endfor %}
        ]
        {%- endif %}
        self.__node_table = {
            {%- for sentence, grammar_tuple in grammar_package.grammar_tuple_map.items() %}
            {{ analyzer_table.sentence_list.index(sentence) }}: {{ grammar_tuple }}
            {%- if not loop.last %},{% endif -%}
            {%- endfor %}
        }
        self.__reduce_symbol_sum = {{ analyzer_table.reduce_symbol_sum }}
        self.__reduce_to_non_terminal_index = {{ analyzer_table.reduce_to_non_terminal_index }}

    def __generate_grammar_tuple(self, statement_index: int, node_tuple: tuple, symbol_package: list):
        grammar_node = {{ configure.boson_option['grammar_node_class_name'] }}()
        for i in node_tuple:
            if isinstance(i, str):
                if i == '$':
                    grammar_node.append(statement_index)
                elif i == '?':
                    grammar_node += symbol_package
                else:
                    if symbol_package:
                        if i[0] == '*':
                            grammar_node += symbol_package[int(i[1:])]
                        else:
                            grammar_node.append(symbol_package[int(i)])
            else:
                if symbol_package:
                    if i[0][0] == '*':
                        for node in symbol_package[int(i[0][1:])]:
                            grammar_node += self.__generate_grammar_tuple(-1, i[1], node)
                    else:
                        for node in symbol_package[int(i[0])]:
                            grammar_node.append(self.__generate_grammar_tuple(-1, i[1], node))
        grammar_node.reduce_number = statement_index
        return grammar_node

    def grammar_analysis(self, token_list):
        grammar = {{ configure.boson_option['grammar_class_name'] }}()
        analysis_stack = [0]
        symbol_stack = []
        token_index = 0
        while token_index < len(token_list):
            token = token_list[token_index]
            current_state = analysis_stack[-1]
            {%- if sparse_table %}
            operation = self.__action_table.get(current_state, {}).get(self.__terminal_index[token.symbol], '{{ configure.boson_table_sign_error }}')
            {%- else %}
            operation = self.__action_table[current_state][self.__terminal_index[token.symbol]]
            {%- endif %}
            operation_flag = operation[0]
            if operation_flag == '{{ configure.boson_table_sign_error }}':
                grammar.error_index = token_index
                return grammar
            elif operation_flag == '{{ configure.boson_table_sign_shift }}':
                state_number = int(operation[1:])
                analysis_stack.append(state_number)
                token_index += 1
                symbol_stack.append(token.text)
            elif operation_flag == '{{ configure.boson_table_sign_reduce }}':
                statement_index = int(operation[1:]) - 1
                reduce_sum = self.__reduce_symbol_sum[statement_index]
                for _ in range(reduce_sum):
                    analysis_stack.pop()
                current_state = analysis_stack[-1]
                current_non_terminal_index = self.__reduce_to_non_terminal_index[statement_index]
                {%- if sparse_table %}
                goto_next_state = self.__goto_table.get(current_state, {}).get(current_non_terminal_index, {{ configure.boson_invalid_goto }})
                {%- else %}
                goto_next_state = self.__goto_table[current_state][current_non_terminal_index]
                {%- endif %}
                if goto_next_state == {{ configure.boson_invalid_goto }}:
                    raise ValueError('Invalid goto action: state={}, non-terminal={}'.format(current_state, current_non_terminal_index))
                analysis_stack.append(goto_next_state)
                {%- if have_special_generate %}
                if statement_index in self.__node_table:
                    symbol_package = []
                    for _ in range(reduce_sum):
                        symbol_package.insert(0, symbol_stack.pop())
                    symbol_stack.append(self.__generate_grammar_tuple(statement_index, self.__node_table[statement_index], symbol_package))
                {%- endif %}
                {%- if have_default_reduce_tuple %}
                {%- if have_special_generate %}
                elif statement_index in [{{ ', '.join(none_grammar_tuple_reduce) }}]:
                {%- else %}
                if statement_index in [{{ ', '.join(none_grammar_tuple_reduce) }}]:
                {%- endif %}
                    grammar_node = {{ configure.boson_option['grammar_node_class_name'] }}()
                    for _ in range(reduce_sum):
                        grammar_node.insert(0, symbol_stack.pop())
                    grammar_node.reduce_number = statement_index
                    symbol_stack.append(grammar_node)
                {%- endif %}
                {%- if have_special_generate or have_default_reduce_tuple %}
                else:
                    raise ValueError('Invalid reduce number: reduce={}'.format(statement_index))
                {%- endif %}
            elif operation_flag == '{{ configure.boson_table_sign_accept }}':
                grammar.grammar_tree = symbol_stack[0]
                return grammar
            else:
                raise ValueError('Invalid action: action={}'.format(operation))
        raise RuntimeError('Analyzer unusual exit.')
{%- if generate_semantics_analyzer %}


class {{ configure.boson_option['semantics_analyzer_class_name'] }}:
    def __init__(self):
        self.__reduce_number_to_grammar_name = {
            {%- for reduce_number, grammar_name in reduce_number_to_grammar_name.items() %}
            {{ reduce_number }}: '{{ grammar_name }}'
            {%- if not loop.last %},{% endif -%}
            {%- endfor %}
        }
        self.__reduce_number_to_grammar_number = {
            {%- for reduce_number, grammar_number in reduce_number_to_grammar_number.items() %}
            {{ reduce_number }}: {{ grammar_number }}
            {%- if not loop.last %},{% endif -%}
            {%- endfor %}
        }
        self.__naive_reduce_number = {{ naive_reduce_number }}
        self.__semantics_entity = {}

    @staticmethod
    def __default_semantics_entity(grammar_entity):
        return grammar_entity

    @staticmethod
    def __naive_semantics_entity(grammar_entity):
        if len(grammar_entity) == 0:
            return None
        elif len(grammar_entity) == 1:
            return grammar_entity[0]
        else:
            return grammar_entity

    def __semantics_analysis(self, grammar_tree: {{ configure.boson_option['grammar_node_class_name'] }}):
        if grammar_tree.reduce_number in self.__reduce_number_to_grammar_name:
            grammar_name = self.__reduce_number_to_grammar_name[grammar_tree.reduce_number]
        elif grammar_tree.reduce_number in self.__reduce_number_to_grammar_number:
            grammar_name = '{{ configure.boson_grammar_name_prefix }}{}'.format(self.__reduce_number_to_grammar_number[grammar_tree.reduce_number])
        else:
            grammar_name = '{{ configure.boson_grammar_name_prefix }}hidden'
        grammar_entity = list(map(lambda g: self.__semantics_analysis(g) if isinstance(g, {{ configure.boson_option['grammar_node_class_name'] }}) else g, grammar_tree.data()))
        if grammar_name in self.__semantics_entity:
            return self.__semantics_entity[grammar_name](grammar_entity)
        elif grammar_tree.reduce_number in self.__naive_reduce_number:
            return self.__naive_semantics_entity(grammar_entity)
        else:
            return self.__default_semantics_entity(grammar_entity)

    def semantics_analysis(self, grammar_tree: {{ configure.boson_option['grammar_node_class_name'] }}):
        return self.__semantics_analysis(grammar_tree)

    def semantics_entity(self, sign):
        def decorator(f):
            if isinstance(sign, int):
                name = '{{ configure.boson_grammar_name_prefix }}{}'.format(sign)
            elif isinstance(sign, str):
                name = sign
            else:
                raise ValueError('Invalid grammar sign: {}'.format(sign))
            self.__semantics_entity[name] = f
            return f
        return decorator
{%- endif %}

